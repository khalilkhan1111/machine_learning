# machine_learning

Machine learning is a subfield of artificial intelligence (AI) that focuses on the development of algorithms and models that enable computers to learn and make predictions or decisions without being explicitly programmed.

Machine learning can be categorized into several types based on the learning approach and the nature of the training data. The three main types of machine learning are:

Supervised Learning:

In supervised learning, the model is trained on a labeled dataset, where each input data point is associated with a corresponding output or target.

The goal is for the model to learn a mapping from inputs to outputs, allowing it to make predictions or classifications on new, unseen data.

Common algorithms used in supervised learning include linear regression, logistic regression, decision trees, support vector machines, and various types of neural networks.

Unsupervised Learning:

Unsupervised learning involves training models on unlabeled data, where the algorithm tries to discover patterns, structures, or relationships within the data.

It is often used for tasks such as clustering (grouping similar data points together) and dimensionality reduction (reducing the number of features while retaining important information).

Common unsupervised learning algorithms include k-means clustering, hierarchical clustering, principal component analysis (PCA), and autoencoders.

Reinforcement Learning:

Reinforcement learning is concerned with training agents to make a sequence of decisions in an environment to maximize a cumulative reward.

The agent learns through trial and error, adjusting its actions based on the rewards it receives from the environment.

Linear Regression:

Linear regression is a fundamental statistical and machine learning technique used for modeling the relationship between a dependent variable (also called the target) and one or more independent variables (predictors or features). It assumes that this relationship is approximately linear, which means that the change in the dependent variable is proportional to changes in the independent variables.

Y = mx + c

where 
y: Dependent variable

x: Independent variable

m : slope of line

c: constant

Best fit line:

Determining the best-fit line in linear regression involves finding the line that minimizes the sum of the squared differences (residuals) between the observed data points and the predicted values generated by the line. To determine best fit line we use sum of squared error and formulae is (actual output - predicted output)**2

Evaluation metrices:

Mean Absolute Error (MAE): MAE calculates the average absolute difference between predicted and actual values. It is robust to outliers. 
Formula is MAE = (1/n) * sum(|y_i - y_pred_i|)

n is the number of data points

y_i is the actual value for the i-th data point

y_pred_i is the predicted value for the i-th data point

Mean Squared Error (MSE): MSE calculates the average squared difference between predicted and actual values. It penalizes larger errors more heavily than MAE.
Formula is (1/n) * sum((y_i - y_pred_i)^2)

n is the number of data points

y_i is the actual value for the i-th data point

y_pred_i is the predicted value for the i-th data point

Root Mean Squared Error (RMSE): RMSE is the square root of MSE and provides an interpretable metric in the same unit as the target variable.
Formula is  RMSE = sqrt(MSE)

MSE is the mean squared error

R-squared (R**2): R-squared measures the proportion of the variance in the dependent variable that is explained by the model. It ranges from 0 to 1, where higher values indicate a better fit.
Formula is R^2 = 1 - (SSR / SST)

SSR is the sum of squared residuals

SST is the sum of squared totals

SSR is the sum of the squared differences between the actual and predicted values for each data point. SST is the sum of the squared differences between each data point and the mean of all data points.

Mean Absolute Percentage Error (MAPE): MAPE calculates the average percentage difference between predicted and actual values. It is often used in forecasting problems.
formula is MAPE = (1/n) * sum(|(y_i - y_pred_i) / y_i| * 100)

n is the number of data points

y_i is the actual value for the i-th data point

y_pred_i is the predicted value for the i-th data point




 
